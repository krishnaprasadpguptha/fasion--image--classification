{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bb88551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0915d6",
   "metadata": {},
   "source": [
    "### Problem statement\n",
    "\n",
    "This notebook demonstrate the end-to-end flow of machine learning classification problem using neural networks from keras library\n",
    "\n",
    "- Training\n",
    "- Validation on a holdout set generated from the original training data\n",
    "- Evaluation on the test data\n",
    "\n",
    "We'll use Fashion Fashion-MNIST data for this example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7032dfe",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "Fashion-MNIST is a dataset of Zalando's article imagesâ€”consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. \n",
    "\n",
    "Zalando intends Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits.\n",
    "\n",
    "Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255. The training and test data sets have 785 columns. The first column consists of the class labels (see above), and represents the article of clothing. The rest of the columns contain the pixel-values of the associated image\n",
    "\n",
    "**Labels**\n",
    "\n",
    "Each training and test example is assigned to one of the following labels:\n",
    "\n",
    "- 0 T-shirt/top\n",
    "- 1 Trouser\n",
    "- 2 Pullover\n",
    "- 3 Dress\n",
    "- 4 Coat\n",
    "- 5 Sandal\n",
    "- 6 Shirt\n",
    "- 7 Sneaker\n",
    "- 8 Bag\n",
    "- 9 Ankle boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2597949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from keras\n",
    "fashion_data = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_data.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee1680a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "decee8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Label : 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f6ffcc7370>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imgIndex = 16\n",
    "img = train_images[imgIndex]\n",
    "print(\"Image Label :\",train_labels[imgIndex])\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddf813f",
   "metadata": {},
   "source": [
    "### Create  neural network\n",
    "When working with input tensors like image datasets, we need to find a way to properly feed them into our input layer.\n",
    "After all, your input data shape needs to match your input layer shape.\n",
    "- Flatten: \n",
    "    Fashion MNIST has 70,000 images in 10 different fashion categories. Each image has 28* 28 pixel resolution. Here we have an issue feeding this multi-dimensional array or tensor into our input layer. In order to converts the multi-dimensional arrays into flattened one-dimensional arrays or single-dimensional arrays we can use Flatten function. **keras.layers.flatten** function flattens the multi-dimensional input tensors into a single dimension, so you can structure your input layer and build your neural network model, then pass those data into every single neuron of the model effectively\n",
    "    \n",
    "    Why do we have to flatten the input data?<br>\n",
    "    - The first layer of a neural network model should have the same shape as the input data. This is a general rule of thumb for neural networks\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f36a3613",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "                    keras.layers.Flatten(input_shape=(28,28)), # first layer with 784 neurons\n",
    "                    keras.layers.Dense(128, activation=tf.nn.relu), # second fully connected layer with 128 neurons\n",
    "                    keras.layers.Dense(128, activation=tf.nn.relu), # third fully connected layer with 128 neurons\n",
    "                    keras.layers.Dense(10, activation=tf.nn.softmax) # output layer with with 10 neurons\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3ffaf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compilation is a step that transforms the simple sequence of layers that we previously defined into a highly efficient series of matrix transformations.\n",
    "model.compile(optimizer = 'adam',\n",
    "           loss = 'sparse_categorical_crossentropy',\n",
    "           metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cfec1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 9s 4ms/step - loss: 2.1610 - accuracy: 0.7477\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.6216 - accuracy: 0.7976\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.5615 - accuracy: 0.8085\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.5004 - accuracy: 0.8239\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.4468 - accuracy: 0.8392\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.4239 - accuracy: 0.8473\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3994 - accuracy: 0.8565\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3831 - accuracy: 0.8620\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3763 - accuracy: 0.8647\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3692 - accuracy: 0.8661\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f6fff1aee0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a1bc6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4248 - accuracy: 0.8534\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4248 - accuracy: 0.8534\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels)\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9069ef87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model accuracy 0.8533999919891357\n"
     ]
    }
   ],
   "source": [
    "print(\"model accuracy\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00e913ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 193ms/step\n",
      "[[8.7657126e-16 1.3648350e-17 7.1672065e-23 1.8363883e-19 2.3302058e-18\n",
      "  4.1342764e-03 8.1167372e-16 9.2818253e-02 2.6355408e-05 9.0302110e-01]\n",
      " [2.1481599e-05 6.9820965e-07 9.5767462e-01 2.1043017e-05 1.4006721e-02\n",
      "  5.3463698e-16 2.8268622e-02 3.0843746e-14 6.9045009e-06 9.5525029e-12]\n",
      " [1.9496013e-16 1.0000000e+00 2.8156070e-25 1.7333222e-10 5.5383021e-17\n",
      "  7.5315752e-37 6.5424960e-15 0.0000000e+00 3.9326261e-17 0.0000000e+00]\n",
      " [1.0771415e-14 1.0000000e+00 9.0340523e-21 1.7213448e-08 4.3172594e-13\n",
      "  5.6190730e-28 2.0684195e-13 0.0000000e+00 5.6106769e-13 8.3296264e-32]\n",
      " [5.6414869e-02 8.3954437e-05 1.9353190e-01 1.0801229e-02 5.6635022e-02\n",
      "  6.6333536e-07 6.7412984e-01 3.0984454e-06 8.3991196e-03 2.8378631e-07]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_images[0:5])\n",
    "\n",
    "# Print the predicted labels\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856a7b66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
